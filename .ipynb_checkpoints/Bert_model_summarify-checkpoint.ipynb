{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgcx4jPKRd8V"
   },
   "source": [
    "Referanslar:\n",
    "\n",
    "* https://mccormickml.com/2019/07/22/BERT-fine-tuning/ \n",
    "* https://www.youtube.com/playlist?list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6\n",
    "* https://www.youtube.com/playlist?list=PLEJK-H61XlwxpfpVzt3oDLQ8vr1XiEhev\n",
    "* Bunlara ek olarak NLP ve Pytorch üzerine udemy kursları."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### İlk olarak Colab ekran kartını kontrol ediyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "id": "lOyJLWyCbZt-",
    "outputId": "b0ec0795-9cb3-4a74-f4ea-6e1f17ecdb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 23 07:35:38 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 455.23.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   40C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                 ERR! |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Colab üzerinden hızlı transfer için veriyi Drive'a yükledim. Drive üzerinden veriyi çekmek ve oluşturduğumuz modeli Drive'a kaydetmek için Drive'ı Colab'e bağlıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Wxy9V880be4F",
    "outputId": "e88b12c0-de9e-4ffc-f3bf-fc98d9220e6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerekli paketler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "RrYO6HDoRNNP",
    "outputId": "f09269eb-d01b-40a4-cf3b-f0415485e700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1MB 19.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Collecting tokenizers==0.9.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9MB 27.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 43.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.0)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=c78b41126f3ff0edbcacc1fd89e15b3d385d477a57676b782f1fb809c5f6f8bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.2 transformers-3.4.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "!pip install transformers\n",
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "OCCSYp9sSlSD",
    "outputId": "f0b5f96e-fa60-40f2-c5bb-bff33466c825"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "# check GPU\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name == '/device:GPU:0':\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dglYrRbCbR8Y"
   },
   "source": [
    "Veriyi \"df\" değişkenine atayıp veri hakkında çeşitli bilgilere bakıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Nt6KR1ZTMEh"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/My Drive/sample_complaint_data_90k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "vaWQQe3yTYab",
    "outputId": "0617d8ff-520b-48f2-9eb5-b44dfe6701cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90000 entries, 0 to 89999\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   text      90000 non-null  object\n",
      " 1   category  90000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 359
    },
    "id": "NOTi-A1UTc24",
    "outputId": "ed92ab78-0211-4042-a537-b147dad590ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84427</th>\n",
       "      <td>Son bir buçuk yıldır işsizim kredimi 1 nisanda...</td>\n",
       "      <td>kredi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29571</th>\n",
       "      <td>Halkbank kredi kartı ve bankamatik kartımı ipt...</td>\n",
       "      <td>iptal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27465</th>\n",
       "      <td>Geçtiğimiz yıllarda üyelik bedeli altında aldı...</td>\n",
       "      <td>iptal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47213</th>\n",
       "      <td>Yaklaşık 3/4 ay kadar önce şahsıma Akbank'dan ...</td>\n",
       "      <td>musteri-hizmetleri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>Akbank 6 yıldır müşterisi olmama rağmen Axess ...</td>\n",
       "      <td>kredi-karti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64811</th>\n",
       "      <td>Modacruz firması 16.02.2018 tarihinde saat 09:...</td>\n",
       "      <td>iade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79197</th>\n",
       "      <td>Temel ihtiyaç kredisi başvurusu 2 nisandan ber...</td>\n",
       "      <td>kredi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23474</th>\n",
       "      <td>Akbank tarafından son hanesi 9942 olan Axess k...</td>\n",
       "      <td>iptal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11242</th>\n",
       "      <td>10 yıllık Akbank müşterisiyim kartınızı çok ak...</td>\n",
       "      <td>kredi-karti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21961</th>\n",
       "      <td>2 ay önce Denizbank GS Bonus kredi kartım kayb...</td>\n",
       "      <td>iptal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text            category\n",
       "84427  Son bir buçuk yıldır işsizim kredimi 1 nisanda...               kredi\n",
       "29571  Halkbank kredi kartı ve bankamatik kartımı ipt...               iptal\n",
       "27465  Geçtiğimiz yıllarda üyelik bedeli altında aldı...               iptal\n",
       "47213  Yaklaşık 3/4 ay kadar önce şahsıma Akbank'dan ...  musteri-hizmetleri\n",
       "6279   Akbank 6 yıldır müşterisi olmama rağmen Axess ...         kredi-karti\n",
       "64811  Modacruz firması 16.02.2018 tarihinde saat 09:...                iade\n",
       "79197  Temel ihtiyaç kredisi başvurusu 2 nisandan ber...               kredi\n",
       "23474  Akbank tarafından son hanesi 9942 olan Axess k...               iptal\n",
       "11242  10 yıllık Akbank müşterisiyim kartınızı çok ak...         kredi-karti\n",
       "21961  2 ay önce Denizbank GS Bonus kredi kartım kayb...               iptal"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hedef değişken eşit bir şekilde dapıtılmış. Bu durum, Bert kendine ait pre-trained tokenizer kullandığı için ve hedef değişken eşit dağıtılmış olduğu için, Veri Manipülasyonu yapmaktan bizi kurtarıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "FEcaS2orThoy",
    "outputId": "5c781515-b4b7-48a6-e3f6-e68fae2fae6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "hesap                 15000\n",
       "iade                  15000\n",
       "iptal                 15000\n",
       "kredi                 15000\n",
       "kredi-karti           15000\n",
       "musteri-hizmetleri    15000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1BW4WCeTb1a5"
   },
   "source": [
    "Kategorik olan hedef değişkeni modelde kullanabilmemiz için kategori kolonunu LabelEncoder metoduyla numerik değerlere atıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOo9dA56_7Oy"
   },
   "outputs": [],
   "source": [
    "df['encoded_categories'] = LabelEncoder().fit_transform(df['category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMsdi2PzcAdY"
   },
   "source": [
    "Türkçe Bert tokenizerını indiriyoruz ve \"tokenizer\" olarak tanımlıyoruz. Yuakrıda bahsettiğim gibi Bert, Vikipedi makaleleri üzerinden eğitilmiş olduğu için kendi tokenizerına sahip. Aslında tokenize etme aşamasına geçmeden önce veri üzerinde temizlik yapılıp yapılmaması gerektiğine bakılmalı. İngilizce dili için Spacy kütüphanesi bu iş için iyi çalışıyor ama Türkçe dili için kaliteli bir NLP kütüphanesi ne yazık ki mevcut değil. Yazım yanlışlarını düzelten bağımsız bir github NLP türkçe kütüphanesi buldum ama kütüphanenin kalitesinden emin olamayacağım için kullanmak istemedim. Bir diğer deyişle kötü bir kütüphaneyle veriyi bozmak istemedim.\n",
    "\n",
    "Zaten bu süreçte deneme yanılma yoluyla bir çok model denediğim için, elimizde mecut bulunan verinin çok da fazla temizlik ihtiyacı olmadığına, tokenizerın gayet düzgün çalıştığına bu deneme yanılma sürecinde tanık oldum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "8ea950bdb1424ee7b35faf70585e7282",
      "698871269282417daa858f1fcb2d49dc",
      "4cee88aaf1ff4efbb6804f40d5d84b24",
      "41d21ebec5c0403fa78e9617df3a0601",
      "4628a90377d84a95a227b068d6698d48",
      "96c8122949cc4cc0885f759fc896d7a8",
      "0167995046fd4b18937628928afe8d65",
      "3bdb579d74944e31a0a60c177f33f9b7",
      "721c364699384dce833cfa6ac754273e",
      "5f54685dbd194d86b75b8cb33df4495c",
      "df86506876b34c389ff5d9a2632e7f5d",
      "e46d58a85e09470f9d729acd093ba691",
      "e9023f773f6e420cadb73cbd3684bea7",
      "24f520ef5bfe42bca2f382604da02f6f",
      "db06218fae9442bea68a880eeaf364f7",
      "89bddd8080b9479d8e10967388653180"
     ]
    },
    "id": "wtmbRhroAtCd",
    "outputId": "dab60f64-8148-4755-b6e0-163725309285"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea950bdb1424ee7b35faf70585e7282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1233088.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "721c364699384dce833cfa6ac754273e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=59.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-turkish-128k-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DzbC8f7AxAC"
   },
   "outputs": [],
   "source": [
    "sentences = df.text.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ep3B9i-043xM"
   },
   "source": [
    "Bert modelinde maksimumtoken sayısı 512 olarak belirlenmiş durumda. Bizim verimizde kelime sayılarının ortalamaları 0-200 kelime arasında. Bert Tokenizer bazı kelimeleri hece olarak ayırdığı için, ortalama token sayısı ortalama kelime sayısından daha çok olacaktır.\n",
    "\n",
    "Daha önce deneme yanılma yoluyla oluşturduğum bir Distilbert modelinde maksimum token sayısını (max_len değişkenini) 512 olarak belirlemiştim ve elde ettiğim model performansı 280'e kıyasla neredeyse hiç fark etmemişti. 100 ve 200 değerlerini denediğimde ise %10'a kadar azalma olduğunu gözlemledim. Kelime sayılarında, Outllier'ı görmezden gelerek baktığımızda 0-200 arasında bir normal dağılım gözlemleniyor, buna Bert Tokenizer'ın kendine özgü tokenize etme yöntemiyle oluşturduğu heceleri de dahil edince 280 değerinin iyi olacağını düşündüm, ve modeli eğittimde, gerçekten de 512 değerinden çok farklı olmadığını gözlemledim.\n",
    "\n",
    "Ek olarak model eğitme hızını hızlandırmak için minimum batch size değerini 32 yapmak istiyordum ve [bu linkte](https://www.youtube.com/watch?v=VRNYw_elzP4) anlatılanlardan yola çıkarak, Colab'de verilen ekran kartlarında(Tesla K80, P100 ve T4 kartları için. P4 6GB RAM'e sahip olduğu için bu duruma dahil değil) min batch size 32 için, maks sequence length'in 280 olabileceğini gözlemledim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pPgQuTUGA1ct"
   },
   "outputs": [],
   "source": [
    "max_len = 280"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCqcXz6scVLD"
   },
   "source": [
    "burada elimizdeki metin verisini %80 ve %20 oranıyla, sırasıyla training ve test olarak ikiye bölüyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsHlvfa1A9J_"
   },
   "outputs": [],
   "source": [
    "training = df.groupby('category').apply(lambda x : x.sample(frac = 0.8))\n",
    "test = pd.concat([df,training]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "qYiFqjplA_e4",
    "outputId": "5d051eb7-d89a-4188-8500-a3e03d37d22e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  72000\n",
      "Test:  18000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training: \", len(training))\n",
    "print(\"Test: \", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PuTo9fHBBFd"
   },
   "outputs": [],
   "source": [
    "training_texts = training.text.values\n",
    "training_labels = training.encoded_categories.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u793WoNkclVP"
   },
   "source": [
    "bu kısımda metin verisini modelde kullanmak üzere işliyoruz. öncelikle cümledeki kelimeler indirdiğimiz tokenizer ile tokenize ediliyor, sonrasında sınıflandırma probleminin çözülebilmesi için gerekli olan token'lar cümlenin sonuna ve başına ekleniyor. cümle maksimum uzunluktan kısaysa, input vektörümüz sabit uzunlukta olduğu için boşluklar dolduruluyor, uzunsa metin limit kadar kelime ile ifade ediliyor. attention mask'leri oluşturuluyor ve metinler işlemin sonucunda tensor objesi olarak geri dönüyor.\n",
    "\n",
    "aşağıdaki çıktıda da görüldüğü üzere, metindeki kelimeler tokenizer'daki kelimelerin id'leri ile ifade ediliyor ve bu şekilde işleme sokuluyor.\n",
    "\n",
    "Bu kısımda modele sunmak üzre input_id ve attention_mask değişkenlerini oluşturuyoruz. Bu işlem için kısaca sınırladığımız maksimum sequence length uyarınca (max_len=280) metinler tokenize ediliyor. Eğer bir satır tokenize edildikten sonra 280'den daha az değere sahipse, eksik olduğu kadar pad ekleniyor (yani 120 uzunluğundaysa 160 adet pad ekleniyor), 280'den fazlaysa 280 değerine kadar kısaltılıyor ve o kısaltılmış haliyle kullanılıyor. Pad'ler basit bir şekilde anlam barındırmayan ekstra 0 değerlerinden oluşuyor. Tokenize edildikten sonra, oluşturulmuş tokenlerin anlamlı oluğ olmadığını modele belirtmek üzere attention mask oluşturuluyor. Örnek olarak bir metin 100 token haline gelmişse ve maksimum sequence length'e ulaşması için sonuna 180 tane pad eklenmişse, sadece bu ilk 100 tokenin anlam barındırdığını, son 180 tokenin anlam barındırmadığını ifade eden bir attention mask üretiliyor. Bu Attention Mask'in formatından emin değilim ancak binary olduğunu düşünüyorum, az önceki örnekteki metin için oluşturulan attention mask için ilk 100 değerde 1'ler, sonraki 180 değerde ise 0'lar barınıdırıyor olabilir. Son olarak, oluşturudğumuz bu değerleri modelde kullanabilmek için tensor haline getiriyoruz. Tokenizasyon'dan sonraki hali, orjinal metin ile kıyaslanarak hücre çıktısında görülebilir.\n",
    "\n",
    "Not: Aslında bu noktada padding uygulamadan token miktarı dağılıma grafik olarak bakmak isterdim ama bu notebook'u cuma günü oluşturduğum için ve notebook'un yorum kısımlarını yazmayı son gün, son saate bıraktığım için bütün hücreleri tekrardan çalıştırmaya vaktim yok. Başka bir zaman daha detaylı bir Bert Tokenization araştırması yapılabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "AavMUW7oBESR",
    "outputId": "87804b89-c7dc-4e44-e2fb-177c9384fc34"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Banka hesabından 3 adet otomatik çekilen ücret bulunmaktadır. Bu konu hakkında telefon bankacılığını aradım ama yardımcı olamadılar. Telefon bankacılığı ise benim internette gördüğüm bilgileri görebiliyor ekstra bilgi veremediler ve tatmin olmadım. Telefona gelen 2 adet SMS'te ayın 17 sinde 2 adet sigortam olduğunu ve otomatik para çekileceği yazıyordu. \n",
      "Bu ayın 3' ünde 3 ayrı kalemde farklı fiyattan hesabımdan para çekilmiş. Bu konu hakkında bilgi almam lazım. Telefonla Beylikdüzü şubemle görüşmeye çalıştım. 2 saat boyunca kimseye ulaşamadım. \n",
      "Hesaplarımın incelenerek bana yardımcı olunmasını istiyorum. Poliçeleri kontrol ettiğimde 2 adet poliçenin çekildiği gözüküyor.\n",
      "Token IDs: tensor([     2,   3730,  14845,     23,   3764,   5774,  93844,   2074,  45298,\n",
      "          4698,     18,   1964,   2580,   2826,   3035,  32521,  49313,  18847,\n",
      "         17300,   2156,   3679,  94826,     18,   3035,  32521,  49313,   2319,\n",
      "          2633,  13201, 118840,   5130,  22586,   6356,  10242,   2990,  64853,\n",
      "          1944,   1946,   9733,  31271,     18,  21426,   2630,     22,   3764,\n",
      "         12663,     11,   2482,  10906,   3332,  18860,     22,   3764,  73794,\n",
      "         15053,   1946,   5774,   2962,  93844,  76321,   2242,  31425,     18,\n",
      "          1964,  10906,     23,     11,  29257,   1011,     23,   2613,  65113,\n",
      "          2693,  34022, 105879,   2962,  93844,  21888,   1967,     18,   1964,\n",
      "          2580,   2826,   2990,  19620,   4506,     18,  12782,  73721,  12305,\n",
      "         64137,  53874,   2617,  52565,   2941,     18,     22,   2625,   3704,\n",
      "          8995,  57179,   7775,     18,  16904,  52183,  36203,   2789,   3679,\n",
      "         78643,   3719,     18, 100187,   2023,   3140, 100614,   1942,     22,\n",
      "          3764, 100187,   8117,  93844,   9910,  32014,  97730,   2407,     18,\n",
      "             3,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in training_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,      \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True, \n",
    "                        return_tensors = 'pt',\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(training_labels)\n",
    "\n",
    "print('Original: ', training_texts[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensor veri seti haline getiriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4YUhZxyCwVF"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(input_ids, attention_masks, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYQJJAr1e_a4"
   },
   "source": [
    "Oluşturduğumuz tensor verisini modele vermek üzere *dataloader* değişkenine dönüştürüyoruz.\n",
    "\n",
    "Yukarıda da belirtiğim üzere 280 sequence length için seçilebilecek maksimum batch size değeri 32 olduğundan bu değeri bu şekilde seçiyorum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTUsi4QGBxQr"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), \n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model'de kullanmak üzere hedef değişkenin kaç farklı değişkenden oluştuğunu belirliyoruz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dxa9wOcVCzq8"
   },
   "outputs": [],
   "source": [
    "number_of_categories = len(df['encoded_categories'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zow9XGXVfNhS"
   },
   "source": [
    "Pre-Trained Bert Base Türkçe modelini indiriyoruz.\n",
    "\n",
    "Bı kısımda, OOP konusunda çok tecrübesiz olduğum için, modeli sıfırdan oluşturduğumuz bir class üzerinden tanımlamak yerine transformers kütüphanesi içinde hazır bulunan BertForSequenceClassification class'ını kullanıyorum. Bu class içerisinde Classification için ihtiyacımız olan bütün fonksiyonlar tanımlı bulunuyor.\n",
    "\n",
    "En altta *model.cuda()* metotu ile modelin GPU'da kullanılacağını belirtiyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "887040c4274841dd9b80057ca035f945",
      "eb2d93e86ca045f48ee52a4dc23e9841",
      "e00065d8d3914024be86bdea44b1b469",
      "4ecc9ad5459b4f0282aae73d5d3cfd97",
      "10f961283d034f72929795abd63c858f",
      "849b69ea18db4bf3b87f673ceb75db49",
      "fd0ba4182f09496388bf924f5b932289",
      "d7ec6efb919c42e4b42c800562f42d35",
      "710091eeb26b4f2086f51bf56f9f3c56",
      "27f4f67d060a40969e02ff75db7b806d",
      "66806ca0eda348f6b5f91e5bdf64a0bf",
      "d4aea7d8ca99484caf1b75c1bef0707c",
      "ce9d8126c6334a2cade90f6c2b14ff67",
      "9b031b99127f48c3bf053025905c0f95",
      "b22b10804aba4256b149c71491ade908",
      "b46cfc5fb2a84478bfed3a732f335eca"
     ]
    },
    "id": "QfNDxpE3C2bP",
    "outputId": "4ee874d0-a885-4e8d-e1d5-63104ba7c0cd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887040c4274841dd9b80057ca035f945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=386.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710091eeb26b4f2086f51bf56f9f3c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=740314769.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(128000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"dbmdz/bert-base-turkish-128k-uncased\",\n",
    "    num_labels = number_of_categories, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZoEqn64XfjX3"
   },
   "source": [
    "### Hiperparametreler\n",
    "\n",
    "Training'e başlamadan önce, toplam epoch sayısını ve kullancağımız optimizer'ı belirliyoruz. AdamW kullanmamın  belirli bir sebebi yok, sequence classification için herkesin Adam kullandığını gördüğüm için ben de onu seçtim.\n",
    "\n",
    "Başlangıç (initial) Learning rate değerini 0.0001 olarak seçmenin sebebi ise yine deneme yanılma yöntemiyle daha önceden oluşturduğum modeller sonucuyla vardığım bir değer. 0.0001 değeri hem standart 2e-5 değerine kıyasla daha hızlı eğitmeye olanak tanıyor, hem de 2e-5 değerine kıyasla accuracy üzerinde ciddi farklar yaratmıyor. \n",
    "\n",
    "Ek olarak, Ktrain kütüphanesinde optimum learning rate değerini simüle eden bir fonksiyon var. Bu fonksiyon ile vardığım değer de yine 0.001 idi.\n",
    "\n",
    "Epsilon değeri (eps = 1e-8) model weightlerini update etmek için kullanılıyor. Bu değerle ilgili çok fazla bilgim olmadığı için default olarak seçtim ve hiç oynamadım.\n",
    "\n",
    "Scheduler ise, seçtimiz parametreler hiperparametre oldukları için, bu değerlerin train süresince değişimini belirli standartlara göre kontrol eden bir fonksiyon. Yine çok detaylı bilgiye sahip olmadığım için ancak bu kadar açıklayabiliyorum. Hugging Face sitesindeki tanım şu şekilde:\n",
    "\n",
    "*Create a schedule with a learning rate that decreases linearly from the initial lr set in the optimizer to 0, after a warmup period during which it increases linearly from 0 to the initial lr set in the optimizer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wPL4qSPkC8hx"
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 0.0001,\n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqFHIKBhE9wv"
   },
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u239XcAe4Uq9"
   },
   "source": [
    "Referans aldığım notebook'taki seed değeriyle aynı seed değerini seçtim. 42 değeri biraz da manidar olduğu için dokunmak istemedim.\n",
    "\n",
    "Modeli 4 epoch boyunca eğitiyoruz. Dataloader'a aktardığımız verisetini, her defasında 32 tane olacak şekilde training boyunca modele veriyoruz. Her bölüm başlamadan önce optimize edilecek loss değeri sıfırlanıyor. Daha sonra test sürecinde eval() metodunun kullanılabilmesi için Modelin train() metodu çağırılıyor çünkü modelin katmanları train ve eval metodlarında farklı olarak davranıyor. dataloader'daki değerler GPU'ya aktarılıyor, gradient değerleri sıfırlanıyor ve output (logit) değerleri oluşuyor ve buna bağlı olarak loss değeri hesaplanıyor. backpropogation ile gradient'ler tekrar hesaplanıyor ve son olarak da learnig rate'le beraber parametreler de optimize ediliyor. her epoch sonunda ortalama loss print ediliyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Or7cXZA9DPs4",
    "outputId": "91a60af9-b47f-44e8-a687-fbef8fd219ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Batch    50  of  2,250.    Elapsed: 0:00:44.\n",
      "Batch   100  of  2,250.    Elapsed: 0:01:27.\n",
      "Batch   150  of  2,250.    Elapsed: 0:02:11.\n",
      "Batch   200  of  2,250.    Elapsed: 0:02:54.\n",
      "Batch   250  of  2,250.    Elapsed: 0:03:38.\n",
      "Batch   300  of  2,250.    Elapsed: 0:04:21.\n",
      "Batch   350  of  2,250.    Elapsed: 0:05:05.\n",
      "Batch   400  of  2,250.    Elapsed: 0:05:48.\n",
      "Batch   450  of  2,250.    Elapsed: 0:06:32.\n",
      "Batch   500  of  2,250.    Elapsed: 0:07:15.\n",
      "Batch   550  of  2,250.    Elapsed: 0:07:59.\n",
      "Batch   600  of  2,250.    Elapsed: 0:08:42.\n",
      "Batch   650  of  2,250.    Elapsed: 0:09:26.\n",
      "Batch   700  of  2,250.    Elapsed: 0:10:09.\n",
      "Batch   750  of  2,250.    Elapsed: 0:10:53.\n",
      "Batch   800  of  2,250.    Elapsed: 0:11:36.\n",
      "Batch   850  of  2,250.    Elapsed: 0:12:20.\n",
      "Batch   900  of  2,250.    Elapsed: 0:13:03.\n",
      "Batch   950  of  2,250.    Elapsed: 0:13:47.\n",
      "Batch 1,000  of  2,250.    Elapsed: 0:14:30.\n",
      "Batch 1,050  of  2,250.    Elapsed: 0:15:14.\n",
      "Batch 1,100  of  2,250.    Elapsed: 0:15:57.\n",
      "Batch 1,150  of  2,250.    Elapsed: 0:16:41.\n",
      "Batch 1,200  of  2,250.    Elapsed: 0:17:24.\n",
      "Batch 1,250  of  2,250.    Elapsed: 0:18:08.\n",
      "Batch 1,300  of  2,250.    Elapsed: 0:18:52.\n",
      "Batch 1,350  of  2,250.    Elapsed: 0:19:35.\n",
      "Batch 1,400  of  2,250.    Elapsed: 0:20:19.\n",
      "Batch 1,450  of  2,250.    Elapsed: 0:21:02.\n",
      "Batch 1,500  of  2,250.    Elapsed: 0:21:46.\n",
      "Batch 1,550  of  2,250.    Elapsed: 0:22:29.\n",
      "Batch 1,600  of  2,250.    Elapsed: 0:23:13.\n",
      "Batch 1,650  of  2,250.    Elapsed: 0:23:56.\n",
      "Batch 1,700  of  2,250.    Elapsed: 0:24:40.\n",
      "Batch 1,750  of  2,250.    Elapsed: 0:25:23.\n",
      "Batch 1,800  of  2,250.    Elapsed: 0:26:07.\n",
      "Batch 1,850  of  2,250.    Elapsed: 0:26:50.\n",
      "Batch 1,900  of  2,250.    Elapsed: 0:27:34.\n",
      "Batch 1,950  of  2,250.    Elapsed: 0:28:17.\n",
      "Batch 2,000  of  2,250.    Elapsed: 0:29:01.\n",
      "Batch 2,050  of  2,250.    Elapsed: 0:29:44.\n",
      "Batch 2,100  of  2,250.    Elapsed: 0:30:28.\n",
      "Batch 2,150  of  2,250.    Elapsed: 0:31:11.\n",
      "Batch 2,200  of  2,250.    Elapsed: 0:31:55.\n",
      "Average training loss: 0.56\n",
      "Training epoch took: 0:32:38\n",
      "======== Epoch 2 / 4 ========\n",
      "Batch    50  of  2,250.    Elapsed: 0:00:44.\n",
      "Batch   100  of  2,250.    Elapsed: 0:01:27.\n",
      "Batch   150  of  2,250.    Elapsed: 0:02:11.\n",
      "Batch   200  of  2,250.    Elapsed: 0:02:54.\n",
      "Batch   250  of  2,250.    Elapsed: 0:03:38.\n",
      "Batch   300  of  2,250.    Elapsed: 0:04:21.\n",
      "Batch   350  of  2,250.    Elapsed: 0:05:05.\n",
      "Batch   400  of  2,250.    Elapsed: 0:05:48.\n",
      "Batch   450  of  2,250.    Elapsed: 0:06:32.\n",
      "Batch   500  of  2,250.    Elapsed: 0:07:15.\n",
      "Batch   550  of  2,250.    Elapsed: 0:07:59.\n",
      "Batch   600  of  2,250.    Elapsed: 0:08:42.\n",
      "Batch   650  of  2,250.    Elapsed: 0:09:26.\n",
      "Batch   700  of  2,250.    Elapsed: 0:10:09.\n",
      "Batch   750  of  2,250.    Elapsed: 0:10:53.\n",
      "Batch   800  of  2,250.    Elapsed: 0:11:36.\n",
      "Batch   850  of  2,250.    Elapsed: 0:12:20.\n",
      "Batch   900  of  2,250.    Elapsed: 0:13:03.\n",
      "Batch   950  of  2,250.    Elapsed: 0:13:47.\n",
      "Batch 1,000  of  2,250.    Elapsed: 0:14:31.\n",
      "Batch 1,050  of  2,250.    Elapsed: 0:15:14.\n",
      "Batch 1,100  of  2,250.    Elapsed: 0:15:58.\n",
      "Batch 1,150  of  2,250.    Elapsed: 0:16:41.\n",
      "Batch 1,200  of  2,250.    Elapsed: 0:17:25.\n",
      "Batch 1,250  of  2,250.    Elapsed: 0:18:08.\n",
      "Batch 1,300  of  2,250.    Elapsed: 0:18:52.\n",
      "Batch 1,350  of  2,250.    Elapsed: 0:19:35.\n",
      "Batch 1,400  of  2,250.    Elapsed: 0:20:19.\n",
      "Batch 1,450  of  2,250.    Elapsed: 0:21:02.\n",
      "Batch 1,500  of  2,250.    Elapsed: 0:21:46.\n",
      "Batch 1,550  of  2,250.    Elapsed: 0:22:29.\n",
      "Batch 1,600  of  2,250.    Elapsed: 0:23:13.\n",
      "Batch 1,650  of  2,250.    Elapsed: 0:23:57.\n",
      "Batch 1,700  of  2,250.    Elapsed: 0:24:40.\n",
      "Batch 1,750  of  2,250.    Elapsed: 0:25:24.\n",
      "Batch 1,800  of  2,250.    Elapsed: 0:26:07.\n",
      "Batch 1,850  of  2,250.    Elapsed: 0:26:51.\n",
      "Batch 1,900  of  2,250.    Elapsed: 0:27:34.\n",
      "Batch 1,950  of  2,250.    Elapsed: 0:28:18.\n",
      "Batch 2,000  of  2,250.    Elapsed: 0:29:01.\n",
      "Batch 2,050  of  2,250.    Elapsed: 0:29:45.\n",
      "Batch 2,100  of  2,250.    Elapsed: 0:30:29.\n",
      "Batch 2,150  of  2,250.    Elapsed: 0:31:12.\n",
      "Batch 2,200  of  2,250.    Elapsed: 0:31:56.\n",
      "Average training loss: 0.36\n",
      "Training epoch took: 0:32:39\n",
      "======== Epoch 3 / 4 ========\n",
      "Batch    50  of  2,250.    Elapsed: 0:00:44.\n",
      "Batch   100  of  2,250.    Elapsed: 0:01:27.\n",
      "Batch   150  of  2,250.    Elapsed: 0:02:11.\n",
      "Batch   200  of  2,250.    Elapsed: 0:02:54.\n",
      "Batch   250  of  2,250.    Elapsed: 0:03:38.\n",
      "Batch   300  of  2,250.    Elapsed: 0:04:21.\n",
      "Batch   350  of  2,250.    Elapsed: 0:05:05.\n",
      "Batch   400  of  2,250.    Elapsed: 0:05:48.\n",
      "Batch   450  of  2,250.    Elapsed: 0:06:32.\n",
      "Batch   500  of  2,250.    Elapsed: 0:07:16.\n",
      "Batch   550  of  2,250.    Elapsed: 0:07:59.\n",
      "Batch   600  of  2,250.    Elapsed: 0:08:42.\n",
      "Batch   650  of  2,250.    Elapsed: 0:09:26.\n",
      "Batch   700  of  2,250.    Elapsed: 0:10:10.\n",
      "Batch   750  of  2,250.    Elapsed: 0:10:53.\n",
      "Batch   800  of  2,250.    Elapsed: 0:11:37.\n",
      "Batch   850  of  2,250.    Elapsed: 0:12:20.\n",
      "Batch   900  of  2,250.    Elapsed: 0:13:04.\n",
      "Batch   950  of  2,250.    Elapsed: 0:13:47.\n",
      "Batch 1,000  of  2,250.    Elapsed: 0:14:31.\n",
      "Batch 1,050  of  2,250.    Elapsed: 0:15:14.\n",
      "Batch 1,100  of  2,250.    Elapsed: 0:15:58.\n",
      "Batch 1,150  of  2,250.    Elapsed: 0:16:42.\n",
      "Batch 1,200  of  2,250.    Elapsed: 0:17:25.\n",
      "Batch 1,250  of  2,250.    Elapsed: 0:18:09.\n",
      "Batch 1,300  of  2,250.    Elapsed: 0:18:52.\n",
      "Batch 1,350  of  2,250.    Elapsed: 0:19:36.\n",
      "Batch 1,400  of  2,250.    Elapsed: 0:20:19.\n",
      "Batch 1,450  of  2,250.    Elapsed: 0:21:03.\n",
      "Batch 1,500  of  2,250.    Elapsed: 0:21:46.\n",
      "Batch 1,550  of  2,250.    Elapsed: 0:22:30.\n",
      "Batch 1,600  of  2,250.    Elapsed: 0:23:13.\n",
      "Batch 1,650  of  2,250.    Elapsed: 0:23:57.\n",
      "Batch 1,700  of  2,250.    Elapsed: 0:24:41.\n",
      "Batch 1,750  of  2,250.    Elapsed: 0:25:24.\n",
      "Batch 1,800  of  2,250.    Elapsed: 0:26:08.\n",
      "Batch 1,850  of  2,250.    Elapsed: 0:26:51.\n",
      "Batch 1,900  of  2,250.    Elapsed: 0:27:35.\n",
      "Batch 1,950  of  2,250.    Elapsed: 0:28:18.\n",
      "Batch 2,000  of  2,250.    Elapsed: 0:29:02.\n",
      "Batch 2,050  of  2,250.    Elapsed: 0:29:45.\n",
      "Batch 2,100  of  2,250.    Elapsed: 0:30:29.\n",
      "Batch 2,150  of  2,250.    Elapsed: 0:31:12.\n",
      "Batch 2,200  of  2,250.    Elapsed: 0:31:56.\n",
      "Average training loss: 0.26\n",
      "Training epoch took: 0:32:40\n",
      "======== Epoch 4 / 4 ========\n",
      "Batch    50  of  2,250.    Elapsed: 0:00:44.\n",
      "Batch   100  of  2,250.    Elapsed: 0:01:27.\n",
      "Batch   150  of  2,250.    Elapsed: 0:02:11.\n",
      "Batch   200  of  2,250.    Elapsed: 0:02:54.\n",
      "Batch   250  of  2,250.    Elapsed: 0:03:38.\n",
      "Batch   300  of  2,250.    Elapsed: 0:04:21.\n",
      "Batch   350  of  2,250.    Elapsed: 0:05:05.\n",
      "Batch   400  of  2,250.    Elapsed: 0:05:48.\n",
      "Batch   450  of  2,250.    Elapsed: 0:06:32.\n",
      "Batch   500  of  2,250.    Elapsed: 0:07:15.\n",
      "Batch   550  of  2,250.    Elapsed: 0:07:59.\n",
      "Batch   600  of  2,250.    Elapsed: 0:08:42.\n",
      "Batch   650  of  2,250.    Elapsed: 0:09:26.\n",
      "Batch   700  of  2,250.    Elapsed: 0:10:10.\n",
      "Batch   750  of  2,250.    Elapsed: 0:10:53.\n",
      "Batch   800  of  2,250.    Elapsed: 0:11:37.\n",
      "Batch   850  of  2,250.    Elapsed: 0:12:20.\n",
      "Batch   900  of  2,250.    Elapsed: 0:13:04.\n",
      "Batch   950  of  2,250.    Elapsed: 0:13:47.\n",
      "Batch 1,000  of  2,250.    Elapsed: 0:14:31.\n",
      "Batch 1,050  of  2,250.    Elapsed: 0:15:14.\n",
      "Batch 1,100  of  2,250.    Elapsed: 0:15:58.\n",
      "Batch 1,150  of  2,250.    Elapsed: 0:16:41.\n",
      "Batch 1,200  of  2,250.    Elapsed: 0:17:25.\n",
      "Batch 1,250  of  2,250.    Elapsed: 0:18:08.\n",
      "Batch 1,300  of  2,250.    Elapsed: 0:18:52.\n",
      "Batch 1,350  of  2,250.    Elapsed: 0:19:36.\n",
      "Batch 1,400  of  2,250.    Elapsed: 0:20:19.\n",
      "Batch 1,450  of  2,250.    Elapsed: 0:21:03.\n",
      "Batch 1,500  of  2,250.    Elapsed: 0:21:46.\n",
      "Batch 1,550  of  2,250.    Elapsed: 0:22:30.\n",
      "Batch 1,600  of  2,250.    Elapsed: 0:23:13.\n",
      "Batch 1,650  of  2,250.    Elapsed: 0:23:57.\n",
      "Batch 1,700  of  2,250.    Elapsed: 0:24:40.\n",
      "Batch 1,750  of  2,250.    Elapsed: 0:25:24.\n",
      "Batch 1,800  of  2,250.    Elapsed: 0:26:07.\n",
      "Batch 1,850  of  2,250.    Elapsed: 0:26:51.\n",
      "Batch 1,900  of  2,250.    Elapsed: 0:27:34.\n",
      "Batch 1,950  of  2,250.    Elapsed: 0:28:18.\n",
      "Batch 2,000  of  2,250.    Elapsed: 0:29:01.\n",
      "Batch 2,050  of  2,250.    Elapsed: 0:29:45.\n",
      "Batch 2,100  of  2,250.    Elapsed: 0:30:28.\n",
      "Batch 2,150  of  2,250.    Elapsed: 0:31:12.\n",
      "Batch 2,200  of  2,250.    Elapsed: 0:31:55.\n",
      "Average training loss: 0.15\n",
      "Training epoch took: 0:32:39\n",
      "Training completed in 2:10:36 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "# Bu training kodu aşağıdaki linktedi `run_glue.py` script'i baz alınarak oluşturulmuştur:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        total_train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Training completed in {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGlqNzzN3f0K"
   },
   "source": [
    "training'deki model performansı incelemek için loss'daki düşüşü inceliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "QEX93h5OE-pG",
    "outputId": "dcad641a-903e-4b9a-e5f6-af5e728db0c9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "plt.plot(df_stats['Training Loss'], label=\"Training\")\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQ6RTYEu3nwL"
   },
   "source": [
    "training verisetinde olduğu gibi, test veriseti için de bir dataloader oluşturuyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Xa3aIdMyJwm-",
    "outputId": "58bb17db-59aa-4975-97e3-ea5131aa4764"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "test_texts = test.text.values\n",
    "test_labels = test.encoded_categories.values\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for text in test_texts:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        text,                     \n",
    "                        add_special_tokens = True, \n",
    "                        max_length = max_len,          \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,  \n",
    "                        return_tensors = 'pt',   \n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(test_labels)\n",
    "\n",
    "batch_size = 32  \n",
    "\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RxGSl8Efe8JM"
   },
   "source": [
    "test verisini kullanarak modele sonuçları tahmin ettiriyoruz. batch değerimiz 32 olduğu için, model training'de olduğu gibi prediction kısmında da 32'şer 32'şer input'ları modele veriyor. o yüzden flatten fonksiyonu ile bütün sonuçları tek bir listede topluyoruz ve prediction_set değişkeninde saklıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "8RNfzOIZKH82",
    "outputId": "2e519706-846f-4603-8a75-054e382160f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction started on test data\n",
      "Prediction completed\n"
     ]
    }
   ],
   "source": [
    "print('Prediction started on test data')\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for batch in prediction_dataloader:\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  with torch.no_grad():\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('Prediction completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNJdxER7KeBH"
   },
   "outputs": [],
   "source": [
    "prediction_set = []\n",
    "\n",
    "for i in range(len(true_labels)):\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  prediction_set.append(pred_labels_i)\n",
    "\n",
    "prediction_scores = [item for sublist in prediction_set for item in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZXQhPf8fCdb"
   },
   "source": [
    "Bu kısımda Precision, Recall ve F-score değerlerini çıkartıyoruz, modelin performansını gözlemliyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tk4NmFh0KjLu"
   },
   "outputs": [],
   "source": [
    "f_score = f1_score(test_labels, prediction_scores, average='macro')\n",
    "precision = precision_score(test_labels, prediction_scores, average='macro')\n",
    "recall = recall_score(test_labels, prediction_scores, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kF8xMzqe3wqV"
   },
   "source": [
    "Sequence length'i 280'e kısıtlamış olsak da gayet iyi bir F-Score ve Precision elde edebildik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "BQaJueaUKlQf",
    "outputId": "43255640-ce1f-4c49-dc0a-47b773d1d4af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score:  0.878444187384857\n",
      "Recall:  0.8784999999999998\n",
      "Precision:  0.8785004569575245\n"
     ]
    }
   ],
   "source": [
    "print(\"F-Score: \", f_score)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"Precision: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTaAxtnyKnzf"
   },
   "outputs": [],
   "source": [
    "report = pd.DataFrame(classification_report(test_labels, prediction_scores, output_dict=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyJ5RCD-Kqur"
   },
   "outputs": [],
   "source": [
    "report = report.rename(columns={'0':'hesap',\n",
    "                          '1':'iade',\n",
    "                          '2':'iptal',\n",
    "                          '3':'kredi',\n",
    "                          '4':'kredi-karti',\n",
    "                          '5':'musteri-hizmetleri'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "id": "Zjp7m2NRMoRp",
    "outputId": "6b6fa0f1-e988-4bbd-da31-51440b3f6599"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hesap</th>\n",
       "      <th>iade</th>\n",
       "      <th>iptal</th>\n",
       "      <th>kredi</th>\n",
       "      <th>kredi-karti</th>\n",
       "      <th>musteri-hizmetleri</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.875342</td>\n",
       "      <td>0.854449</td>\n",
       "      <td>0.907377</td>\n",
       "      <td>0.902225</td>\n",
       "      <td>0.840225</td>\n",
       "      <td>0.891385</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.854333</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.930667</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.886333</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.878500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.864710</td>\n",
       "      <td>0.857712</td>\n",
       "      <td>0.918874</td>\n",
       "      <td>0.897083</td>\n",
       "      <td>0.843434</td>\n",
       "      <td>0.888852</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>0.878444</td>\n",
       "      <td>0.878444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>0.8785</td>\n",
       "      <td>18000.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 hesap         iade  ...     macro avg  weighted avg\n",
       "precision     0.875342     0.854449  ...      0.878500      0.878500\n",
       "recall        0.854333     0.861000  ...      0.878500      0.878500\n",
       "f1-score      0.864710     0.857712  ...      0.878444      0.878444\n",
       "support    3000.000000  3000.000000  ...  18000.000000  18000.000000\n",
       "\n",
       "[4 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Son olarak, api'de kullanmak üzere modeli ve tokenizer'ı Drive'a kaydediyoruz. Bunun için transformers'ın save_pretrained methodunu kullanıyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvwqtZhhhMKi"
   },
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('/content/drive/My Drive/bert_token_save')\n",
    "model.save_pretrained('/content/drive/My Drive/bert_model_save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "Bu notebook'da oluşturulan model için kurulan api'yi, github repo'sunda Bert_app adlı klasörün içinde bulabilirsiniz.\n",
    "Api'yi FastAPI kullanarak oluşturdum."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of classification_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0167995046fd4b18937628928afe8d65": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "10f961283d034f72929795abd63c858f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "24f520ef5bfe42bca2f382604da02f6f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27f4f67d060a40969e02ff75db7b806d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3bdb579d74944e31a0a60c177f33f9b7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41d21ebec5c0403fa78e9617df3a0601": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bdb579d74944e31a0a60c177f33f9b7",
      "placeholder": "​",
      "style": "IPY_MODEL_0167995046fd4b18937628928afe8d65",
      "value": " 1.23M/1.23M [00:05&lt;00:00, 241kB/s]"
     }
    },
    "4628a90377d84a95a227b068d6698d48": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "4cee88aaf1ff4efbb6804f40d5d84b24": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96c8122949cc4cc0885f759fc896d7a8",
      "max": 1233088,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4628a90377d84a95a227b068d6698d48",
      "value": 1233088
     }
    },
    "4ecc9ad5459b4f0282aae73d5d3cfd97": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d7ec6efb919c42e4b42c800562f42d35",
      "placeholder": "​",
      "style": "IPY_MODEL_fd0ba4182f09496388bf924f5b932289",
      "value": " 386/386 [00:56&lt;00:00, 6.87B/s]"
     }
    },
    "5f54685dbd194d86b75b8cb33df4495c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66806ca0eda348f6b5f91e5bdf64a0bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b031b99127f48c3bf053025905c0f95",
      "max": 740314769,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ce9d8126c6334a2cade90f6c2b14ff67",
      "value": 740314769
     }
    },
    "698871269282417daa858f1fcb2d49dc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "710091eeb26b4f2086f51bf56f9f3c56": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_66806ca0eda348f6b5f91e5bdf64a0bf",
       "IPY_MODEL_d4aea7d8ca99484caf1b75c1bef0707c"
      ],
      "layout": "IPY_MODEL_27f4f67d060a40969e02ff75db7b806d"
     }
    },
    "721c364699384dce833cfa6ac754273e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df86506876b34c389ff5d9a2632e7f5d",
       "IPY_MODEL_e46d58a85e09470f9d729acd093ba691"
      ],
      "layout": "IPY_MODEL_5f54685dbd194d86b75b8cb33df4495c"
     }
    },
    "849b69ea18db4bf3b87f673ceb75db49": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "887040c4274841dd9b80057ca035f945": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e00065d8d3914024be86bdea44b1b469",
       "IPY_MODEL_4ecc9ad5459b4f0282aae73d5d3cfd97"
      ],
      "layout": "IPY_MODEL_eb2d93e86ca045f48ee52a4dc23e9841"
     }
    },
    "89bddd8080b9479d8e10967388653180": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ea950bdb1424ee7b35faf70585e7282": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4cee88aaf1ff4efbb6804f40d5d84b24",
       "IPY_MODEL_41d21ebec5c0403fa78e9617df3a0601"
      ],
      "layout": "IPY_MODEL_698871269282417daa858f1fcb2d49dc"
     }
    },
    "96c8122949cc4cc0885f759fc896d7a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b031b99127f48c3bf053025905c0f95": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b22b10804aba4256b149c71491ade908": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b46cfc5fb2a84478bfed3a732f335eca": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce9d8126c6334a2cade90f6c2b14ff67": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d4aea7d8ca99484caf1b75c1bef0707c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b46cfc5fb2a84478bfed3a732f335eca",
      "placeholder": "​",
      "style": "IPY_MODEL_b22b10804aba4256b149c71491ade908",
      "value": " 740M/740M [00:49&lt;00:00, 15.0MB/s]"
     }
    },
    "d7ec6efb919c42e4b42c800562f42d35": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db06218fae9442bea68a880eeaf364f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df86506876b34c389ff5d9a2632e7f5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f520ef5bfe42bca2f382604da02f6f",
      "max": 59,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e9023f773f6e420cadb73cbd3684bea7",
      "value": 59
     }
    },
    "e00065d8d3914024be86bdea44b1b469": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_849b69ea18db4bf3b87f673ceb75db49",
      "max": 386,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_10f961283d034f72929795abd63c858f",
      "value": 386
     }
    },
    "e46d58a85e09470f9d729acd093ba691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89bddd8080b9479d8e10967388653180",
      "placeholder": "​",
      "style": "IPY_MODEL_db06218fae9442bea68a880eeaf364f7",
      "value": " 59.0/59.0 [00:00&lt;00:00, 64.5B/s]"
     }
    },
    "e9023f773f6e420cadb73cbd3684bea7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "eb2d93e86ca045f48ee52a4dc23e9841": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd0ba4182f09496388bf924f5b932289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
